name: Build and Publish Linux Wheels

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
    - name: Install uv
      run: curl -LsSf https://astral.sh/uv/install.sh | sh
    - name: Create virtual environment
      run: uv venv
    - name: Install maturin
      run: uv pip install maturin[patchelf]
    - name: Run Rust tests
      run: cargo test --verbose
    - name: Install Python dependencies and run Python tests
      run: |
        uv pip install pytest pandas pyarrow
        uv run maturin develop
        uv run python -m pytest tests/test_bitemporal.py -v
    - name: Build release binary (smoke test)
      run: |
        # Build release binary to ensure it compiles correctly
        cargo build --release

  build-linux-wheels:
    needs: test
    runs-on: ubuntu-latest
    strategy:
      matrix:
        target: [x86_64]
        python-version: ['3.9', '3.10', '3.11', '3.12']
    steps:
    - uses: actions/checkout@v4

    - name: Extract version from tag
      id: version
      run: |
        if [[ "${{ github.ref }}" == refs/tags/v* ]]; then
          VERSION=${GITHUB_REF#refs/tags/v}
          echo "VERSION=$VERSION" >> $GITHUB_OUTPUT
          echo "Building version: $VERSION"
        else
          echo "VERSION=0.1.0-dev" >> $GITHUB_OUTPUT
          echo "Building development version"
        fi

    - name: Update version in files
      if: startsWith(github.ref, 'refs/tags/v')
      run: |
        VERSION=${{ steps.version.outputs.VERSION }}
        echo "Updating version to: $VERSION"

        # Update Cargo.toml
        sed -i "s/^version = \".*\"/version = \"$VERSION\"/" Cargo.toml

        # Update pyproject.toml
        sed -i "s/^version = \".*\"/version = \"$VERSION\"/" pyproject.toml

        # Verify changes
        echo "Updated Cargo.toml:"
        grep "^version" Cargo.toml
        echo "Updated pyproject.toml:"
        grep "^version" pyproject.toml

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        targets: ${{ matrix.target }}-unknown-linux-gnu
    - name: Install uv
      run: curl -LsSf https://astral.sh/uv/install.sh | sh
    - name: Create virtual environment
      run: uv venv
    - name: Install maturin
      run: uv pip install maturin[patchelf]
    - name: Build wheel
      run: |
        # Use the specific Python version set up by actions/setup-python
        PYTHON_PATH=$(which python3)
        echo "Using Python interpreter: $PYTHON_PATH (${{ matrix.python-version }})"
        python3 --version

        # Build wheel for this specific Python version
        uv run maturin build --release --out dist --interpreter $PYTHON_PATH
    - name: List built wheels
      run: ls -la dist/
    - name: Upload wheel as artifact
      uses: actions/upload-artifact@v4
      with:
        name: wheels-linux-${{ matrix.target }}-py${{ matrix.python-version }}
        path: dist/*.whl

  publish-release:
    needs: [build-linux-wheels, benchmarks]
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    permissions:
      contents: write
    steps:
    - uses: actions/checkout@v4

    - name: Extract version from tag
      id: version
      run: |
        VERSION=${GITHUB_REF#refs/tags/v}
        echo "VERSION=$VERSION" >> $GITHUB_OUTPUT
        echo "FULL_TAG=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT

    - name: Download all wheel artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: wheels-linux-*
        path: dist-all/
        
    - name: Download benchmark artifacts
      uses: actions/download-artifact@v4
      with:
        name: benchmarks-${{ steps.version.outputs.FULL_TAG }}
        path: benchmark-artifacts/
        
    - name: Flatten wheel directory
      run: |
        mkdir -p dist/
        find dist-all/ -name "*.whl" -exec cp {} dist/ \;
        ls -la dist/
        
    - name: Prepare release assets
      run: |
        mkdir -p release-assets/
        # Copy wheels
        cp dist/*.whl release-assets/
        # Copy benchmark ZIP
        find benchmark-artifacts/ -name "*.zip" -exec cp {} release-assets/ \;
        ls -la release-assets/
        
    - name: Upload GitHub Release
      uses: softprops/action-gh-release@v1
      with:
        tag_name: ${{ github.ref_name }}
        name: Release ${{ steps.version.outputs.VERSION }}
        files: release-assets/*
        generate_release_notes: true
        body: |
          ## Installation
          ```bash
          pip install --no-index --find-links="https://github.com/${{ github.repository }}/releases/download/${{ github.ref_name }}" pytemporal==${{ steps.version.outputs.VERSION }}
          ```

          ## Performance Documentation
          üìä **[View Interactive Benchmark Reports](https://gingermike.github.io/pytemporal/)**
          
          üì¶ **Download Complete Benchmark Data**: `benchmarks-${{ steps.version.outputs.FULL_TAG }}.zip` (includes flamegraphs)

          ## Linux Wheels Built
          - x86_64 (Intel/AMD 64-bit) for Python 3.9, 3.10, 3.11, 3.12

          ## Features
          - High-performance bitemporal timeseries processing  
          - Microsecond precision timestamps for audit trails
          - Conflation optimization for reduced storage
          - Adaptive parallelisation for large datasets
          
          ## Performance Benchmarks
          - üìà [Benchmark Dashboard](https://gingermike.github.io/pytemporal/bench/) - Historical trends
          - üìä [Criterion Reports](https://gingermike.github.io/pytemporal/bench/criterion/report/) - Detailed analysis

          Typical performance (v${{ steps.version.outputs.VERSION }}):
          - Small Dataset (5 records): ~30-35 ¬µs
          - Medium Dataset (100 records): ~165-170 ¬µs
          - Large Dataset (500k records): ~900-950 ms
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  benchmarks:
    needs: test
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    permissions:
      contents: write
    steps:
    - uses: actions/checkout@v4

    - name: Extract version from tag
      id: version
      run: |
        VERSION=${GITHUB_REF#refs/tags/v}
        echo "VERSION=$VERSION" >> $GITHUB_OUTPUT
        echo "FULL_TAG=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
        echo "Building benchmarks for version: $VERSION"

    - name: Update version in files
      run: |
        VERSION=${{ steps.version.outputs.VERSION }}
        sed -i "s/^version = \".*\"/version = \"$VERSION\"/" Cargo.toml
        sed -i "s/^version = \".*\"/version = \"$VERSION\"/" pyproject.toml

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable

    - name: Install uv
      run: curl -LsSf https://astral.sh/uv/install.sh | sh

    - name: Install Python dependencies
      run: uv sync --group dev

    - name: Build Python module
      run: uv run maturin develop --release

    - name: Run Rust benchmarks with flamegraphs
      run: |
        echo "ü¶Ä Running Rust benchmarks..."

        # First run all benchmarks to generate HTML reports
        cargo bench --bench bitemporal_benchmarks small_dataset
        cargo bench --bench bitemporal_benchmarks medium_dataset
        cargo bench --bench bitemporal_benchmarks conflation_effectiveness
        cargo bench --bench bitemporal_benchmarks "scaling_by_dataset_size/records/10"
        cargo bench --bench bitemporal_benchmarks "scaling_by_dataset_size/records/50"
        cargo bench --bench bitemporal_benchmarks "scaling_by_dataset_size/records/100"
        cargo bench --bench bitemporal_benchmarks "scaling_by_dataset_size/records/500"
        cargo bench --bench bitemporal_benchmarks "scaling_by_dataset_size/records/500000"
        cargo bench --bench bitemporal_benchmarks "parallel_effectiveness/scenario/few_ids_many_records"
        cargo bench --bench bitemporal_benchmarks "parallel_effectiveness/scenario/many_ids_few_records"
        cargo bench --bench bitemporal_benchmarks "parallel_effectiveness/scenario/balanced_workload"

        # Now generate flamegraphs for key benchmarks (adds to existing data)
        echo "üî• Generating flamegraphs..."
        cargo bench --bench bitemporal_benchmarks medium_dataset -- --profile-time 3
        cargo bench --bench bitemporal_benchmarks conflation_effectiveness -- --profile-time 3
        cargo bench --bench bitemporal_benchmarks "scaling_by_dataset_size/records/500000" -- --profile-time 2

        echo "‚úÖ Rust benchmarks completed"

    - name: Generate Rust bencher output for tracking
      run: |
        cargo bench --bench bitemporal_benchmarks -- --noplot --output-format bencher | tee rust_bench_output.txt

    - name: Run Python benchmarks
      run: |
        echo "üêç Running Python benchmarks..."
        uv run pytest benches/test_python_benchmarks.py \
          --benchmark-only \
          --benchmark-json=python_bench_output.json \
          --benchmark-sort=name \
          --benchmark-min-rounds=3 \
          -v
        echo "‚úÖ Python benchmarks completed"

    - name: Add flamegraph links to HTML reports
      run: python3 scripts/add_flamegraphs_to_html.py

    - name: Add PyTemporal branding to HTML reports
      run: python3 scripts/add_pytemporal_branding.py

    - name: Create benchmark ZIP artifact
      run: |
        mkdir -p benchmark-artifacts
        cp python_bench_output.json target/criterion/
        cd target/criterion
        zip -r ../../benchmark-artifacts/benchmarks-${{ steps.version.outputs.FULL_TAG }}.zip .

    - name: Upload benchmark ZIP artifact
      uses: actions/upload-artifact@v4
      with:
        name: benchmarks-${{ steps.version.outputs.FULL_TAG }}
        path: benchmark-artifacts/*.zip

    - name: Stash version changes before gh-pages operations
      run: git stash push -- Cargo.toml pyproject.toml Cargo.lock uv.lock

    - name: Push Rust benchmark trends to gh-pages
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: Rust Benchmarks
        tool: 'cargo'
        output-file-path: rust_bench_output.txt
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        benchmark-data-dir-path: 'bench'
        max-items-in-chart: 50

    - name: Push Python benchmark trends to gh-pages
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: Python Benchmarks
        tool: 'pytest'
        output-file-path: python_bench_output.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        benchmark-data-dir-path: 'bench'
        max-items-in-chart: 50

    - name: Deploy criterion reports to gh-pages
      run: |
        # Save criterion reports before switching branches
        mkdir -p /tmp/criterion-reports
        cp -r target/criterion/* /tmp/criterion-reports/
        cp docs/logo.svg /tmp/criterion-reports/ 2>/dev/null || true

        git fetch origin gh-pages
        git checkout gh-pages

        # Copy criterion reports from temp
        mkdir -p bench/criterion
        cp -r /tmp/criterion-reports/* bench/criterion/
        cp /tmp/criterion-reports/logo.svg bench/ 2>/dev/null || true

        # Create landing page with Chart.js for historical trends
        cat > bench/index.html << 'HTMLEOF'
        <!DOCTYPE html>
        <html>
        <head>
            <title>PyTemporal Benchmarks</title>
            <meta charset="utf-8">
            <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js"></script>
            <style>
                body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; margin: 40px; line-height: 1.6; color: #1f2937; }
                .container { max-width: 1200px; margin: 0 auto; }
                h1, h2 { color: #1f2937; }
                .card { background: #f9fafb; border: 1px solid #e5e7eb; border-radius: 8px; padding: 20px; margin: 20px 0; }
                .card h3 { margin-top: 0; color: #3b82f6; }
                a { color: #3b82f6; }
                .btn { display: inline-block; padding: 8px 16px; background: #3b82f6; color: white; text-decoration: none; border-radius: 4px; margin: 5px 5px 5px 0; }
                .btn:hover { background: #1d4ed8; }
                .btn-orange { background: linear-gradient(135deg, #f59e0b, #d97706); }
                .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
                .chart-container { position: relative; height: 350px; margin: 20px 0; }
                .tab-container { display: flex; gap: 10px; margin-bottom: 15px; }
                .tab { padding: 8px 16px; border: 1px solid #e5e7eb; border-radius: 4px; cursor: pointer; background: #fff; }
                .tab.active { background: #3b82f6; color: white; border-color: #3b82f6; }
                .chart-select { padding: 8px 12px; border: 1px solid #e5e7eb; border-radius: 4px; margin-left: auto; }
            </style>
        </head>
        <body>
            <div class="container">
                <div style="display: flex; align-items: center; margin-bottom: 30px; border-bottom: 3px solid #3b82f6; padding-bottom: 20px;">
                    <img src="logo.svg" alt="PyTemporal" width="280" height="80" style="margin-right: 20px;">
                    <div>
                        <h1 style="margin: 0;">Performance Benchmarks</h1>
                        <p style="margin: 5px 0 0 0; color: #6b7280;">High-Performance Bitemporal Processing</p>
                    </div>
                </div>

                <div class="card">
                    <h2>üìà Historical Trends</h2>
                    <div class="tab-container">
                        <button class="tab active" onclick="showChart('rust')">ü¶Ä Rust</button>
                        <button class="tab" onclick="showChart('python')">üêç Python</button>
                        <select class="chart-select" id="benchmarkSelect" onchange="updateChart()">
                            <option value="all">All Benchmarks</option>
                        </select>
                    </div>
                    <div class="chart-container">
                        <canvas id="benchChart"></canvas>
                    </div>
                    <p style="font-size: 0.9em; color: #6b7280;">Data: <a href="data.js">bench/data.js</a></p>
                </div>

                <h2>ü¶Ä Rust Criterion Reports</h2>
                <div class="grid">
                    <div class="card">
                        <h3>Core Benchmarks</h3>
                        <a class="btn" href="criterion/small_dataset/report/">Small Dataset</a>
                        <a class="btn" href="criterion/medium_dataset/report/">Medium Dataset</a>
                        <a class="btn btn-orange" href="criterion/medium_dataset/profile/flamegraph.svg">üî• Flamegraph</a>
                    </div>
                    <div class="card">
                        <h3>Scaling Analysis</h3>
                        <a class="btn" href="criterion/scaling_by_dataset_size/report/">Overview</a>
                        <a class="btn" href="criterion/scaling_by_dataset_size/records/500000/report/">500k Records</a>
                        <a class="btn btn-orange" href="criterion/scaling_by_dataset_size/records/500000/profile/flamegraph.svg">üî• Flamegraph</a>
                    </div>
                    <div class="card">
                        <h3>Parallel & Conflation</h3>
                        <a class="btn" href="criterion/parallel_effectiveness/report/">Parallel Overview</a>
                        <a class="btn" href="criterion/conflation_effectiveness/report/">Conflation</a>
                        <a class="btn btn-orange" href="criterion/conflation_effectiveness/profile/flamegraph.svg">üî• Flamegraph</a>
                    </div>
                </div>

                <div class="card">
                    <h3>üêç Python Benchmarks</h3>
                    <p>Python API benchmarks mirror Rust scenarios. Results in <a href="criterion/python_bench_output.json">JSON format</a>.</p>
                </div>

                <p style="margin-top: 40px; color: #6b7280; text-align: center;">
                    Generated by <a href="https://github.com/bheisler/criterion.rs">Criterion.rs</a> and <a href="https://github.com/benchmark-action/github-action-benchmark">github-action-benchmark</a>
                </p>
            </div>

            <script src="data.js"></script>
            <script>
            let chart = null;
            let currentType = 'rust';
            const colors = ['#3b82f6', '#ef4444', '#22c55e', '#f59e0b', '#8b5cf6', '#ec4899', '#14b8a6', '#f97316'];

            function initChart() {
                if (!window.BENCHMARK_DATA) {
                    document.getElementById('benchChart').parentElement.innerHTML = '<p style="color:#6b7280;text-align:center;padding:40px;">No benchmark data available yet. Data will appear after the first tagged release.</p>';
                    return;
                }
                populateSelect();
                renderChart();
            }

            function populateSelect() {
                const select = document.getElementById('benchmarkSelect');
                const entries = window.BENCHMARK_DATA.entries;
                const benchNames = new Set();
                Object.values(entries).forEach(e => e.benches.forEach(b => benchNames.add(b.name)));
                select.innerHTML = '<option value="all">All Benchmarks</option>';
                [...benchNames].sort().forEach(name => {
                    const opt = document.createElement('option');
                    opt.value = name;
                    opt.textContent = name.length > 40 ? name.slice(0,37) + '...' : name;
                    select.appendChild(opt);
                });
            }

            function showChart(type) {
                currentType = type;
                document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
                event.target.classList.add('active');
                populateSelect();
                renderChart();
            }

            function updateChart() {
                renderChart();
            }

            function renderChart() {
                const entries = window.BENCHMARK_DATA.entries;
                const targetName = currentType === 'rust' ? 'Rust Benchmarks' : 'Python Benchmarks';
                const data = entries[targetName];
                if (!data || !data.benches.length) {
                    document.getElementById('benchChart').parentElement.innerHTML = '<p style="color:#6b7280;text-align:center;padding:40px;">No ' + targetName.toLowerCase() + ' data available.</p>';
                    return;
                }
                const selected = document.getElementById('benchmarkSelect').value;
                const benchmarks = {};
                data.benches.forEach(b => {
                    if (selected !== 'all' && b.name !== selected) return;
                    if (!benchmarks[b.name]) benchmarks[b.name] = [];
                    benchmarks[b.name].push({ commit: b.commit.id.slice(0,7), value: b.value, unit: b.unit });
                });
                const labels = benchmarks[Object.keys(benchmarks)[0]]?.map(d => d.commit) || [];
                const datasets = Object.entries(benchmarks).map(([name, points], i) => ({
                    label: name.length > 30 ? name.slice(0,27) + '...' : name,
                    data: points.map(p => p.value),
                    borderColor: colors[i % colors.length],
                    backgroundColor: colors[i % colors.length] + '20',
                    tension: 0.3,
                    fill: false
                }));
                if (chart) chart.destroy();
                chart = new Chart(document.getElementById('benchChart'), {
                    type: 'line',
                    data: { labels, datasets },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        plugins: { legend: { position: 'bottom', labels: { boxWidth: 12 } } },
                        scales: {
                            y: { title: { display: true, text: currentType === 'rust' ? 'Time (ns)' : 'Iterations/sec' } },
                            x: { title: { display: true, text: 'Commit' } }
                        }
                    }
                });
            }

            document.addEventListener('DOMContentLoaded', initChart);
            </script>
        </body>
        </html>
        HTMLEOF

        git config user.name "GitHub Actions"
        git config user.email "actions@github.com"
        git add bench/
        git commit -m "Update benchmarks for ${{ steps.version.outputs.FULL_TAG }}" || echo "No changes"
        git push origin gh-pages

        # Return to original branch for subsequent jobs
        git checkout -

  publish-pypi:
    needs: build-linux-wheels
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/pytemporal
    permissions:
      id-token: write
    if: startsWith(github.ref, 'refs/tags/v')  # only on version tags
    steps:
      - name: Check out repository (needed by pypa publish action)
        uses: actions/checkout@v4

      - name: Download all built wheel artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: wheels-linux-*
          path: dist-all/
          
      - name: Flatten wheel directory for PyPI
        run: |
          mkdir -p dist/
          find dist-all/ -name "*.whl" -exec cp {} dist/ \;
          ls -la dist/

      - name: Publish package to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages_dir: dist/
          skip_existing: true